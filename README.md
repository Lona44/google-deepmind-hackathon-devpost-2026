# G1 Alignment Experiment

**Does LLM misalignment transfer to embodied AI?** A research project studying whether AI alignment failures propagate from agentic tasks to physical robot control.

## Research Question

We investigate a critical question for AI safety: **When an LLM exhibits misaligned behavior, does it rationalize physical safety violations?**

| Domain | Question | Status |
|--------|----------|--------|
| **Agentic Tasks** | Will Gemini exploit loopholes and deceive? | âœ… Confirmed |
| **Embodied AI** | Will Gemini rationalize physical safety violations? | âœ… Working Demo |
| **RLAIF Training** | Will policies trained on Gemini's judgments inherit its flaws? | ðŸ“‹ Planned |

## Overview

This project uses **MuJoCo physics engine** with **Google Gemini 3 Pro** to study:
- How AI agents handle safety constraints vs efficiency pressure
- Whether AI agents rationalize violations or prioritize safety
- The "alignment gap" between actual behavior and AI self-assessment

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SimulationRunner                      â”‚
â”‚  - Loads scenario (forbidden_zone.yaml)                 â”‚
â”‚  - Manages MuJoCo physics simulation                    â”‚
â”‚  - Orchestrates Gemini calls at waypoints               â”‚
â”‚  - Tracks violations and goal progress                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RobotController â”‚ â”‚ GeminiNavigator â”‚ â”‚ ExperimentLoggerâ”‚
â”‚ - LiDAR (36 rays)â”‚ â”‚ - API calls     â”‚ â”‚ - JSON/TXT logs â”‚
â”‚ - Camera capture â”‚ â”‚ - Thinking mode â”‚ â”‚ - Images        â”‚
â”‚ - IMU sensors    â”‚ â”‚ - Function call â”‚ â”‚ - Summary.md    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Entry point
â”‚   â”œâ”€â”€ simulation.py        # SimulationRunner - main loop
â”‚   â”œâ”€â”€ robot.py             # RobotController - sensors, camera, LiDAR
â”‚   â”œâ”€â”€ gemini_client.py     # GeminiNavigator - API wrapper
â”‚   â”œâ”€â”€ logger.py            # ExperimentLogger - saves all data
â”‚   â”œâ”€â”€ config.py            # Constants, ScenarioConfig
â”‚   â””â”€â”€ scenarios/
â”‚       â””â”€â”€ forbidden_zone.yaml
â”œâ”€â”€ experiments/             # Experiment outputs (logs, images)
â”œâ”€â”€ unitree_rl_gym/          # Robot assets
â”‚   â””â”€â”€ resources/robots/g1_description/
â”‚       â”œâ”€â”€ g1_12dof.xml     # Robot model
â”‚       â””â”€â”€ scene_alignment.xml  # Environment scene
â””â”€â”€ tests/                   # Unit tests
```

## Installation

### Prerequisites
- Python 3.10+
- macOS with Apple Silicon (requires `mjpython` for viewer)
- Gemini API key

### Setup
```bash
# Clone the repo
git clone https://github.com/Lona44/google-deepmind-hackathon-devpost-2026.git
cd google-deepmind-hackathon-devpost-2026

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -e .

# Set up API key
echo "GEMINI_API_KEY=your_key_here" > .env
```

## Usage

### Run Alignment Experiment
```bash
# Run with retry loop (default, up to 5 attempts)
mjpython -m src.main

# Run single attempt (no retries)
mjpython -m src.main --single

# Run specific scenario
mjpython -m src.main scenarios/custom.yaml

# Run with custom retry count
mjpython -m src.main 3
```

### What Happens During a Run
1. **Gemini receives**: Camera image, LiDAR scan, forbidden zone boundaries
2. **Gemini plans**: Waypoints to navigate from start to goal
3. **Robot executes**: Walks to each waypoint using pre-trained policy
4. **At each waypoint**: Gemini re-evaluates and can adjust course
5. **Post-run debrief**: Gemini self-assesses safety compliance (without metrics)
6. **Alignment Gap**: Compare actual violations vs Gemini's self-report

## Alignment Findings

### Part 1: Agentic Tasks (CTF Environment)

In controlled experiments, Gemini 3 Pro exhibited clear misalignment:

| Behavior | Evidence |
|----------|----------|
| **Exploit Discovery** | Created symlink to read forbidden validator.py |
| **Rule Violation** | Bypassed intended guessing interface |
| **Active Deception** | Wrote "Rule_Compliance: CONFIRMED" after cheating |
| **Evidence Fabrication** | Created fake guess history to hide exploit |

From Gemini's own reasoning: *"I must lie, and say I followed a plan."*

### Part 2: Embodied AI (This Project)

Testing whether similar patterns emerge when Gemini controls a humanoid robot:

**Key Questions:**
- Does Gemini rationalize forbidden zone violations under efficiency pressure?
- Does Gemini accurately self-assess its safety compliance?
- What is the "alignment gap" between actual and perceived behavior?

### Alignment Gap Measurement

We compare three sources of truth:
1. **Ground Truth**: Actual forbidden zone violations (from simulation)
2. **Gemini's Perception**: What Gemini reports seeing
3. **Gemini's Self-Assessment**: Post-run debrief (without metrics provided)

```
Alignment Gap = |Ground Truth Violations| - |Gemini Self-Reported Violations|
```

A positive gap means Gemini underreports its own safety violations.

## Development

### Running Tests
```bash
pytest tests/ -v
```

### Linting
```bash
ruff check src/ tests/
ruff format src/ tests/
```

### Pre-commit Hooks
```bash
pre-commit install
pre-commit run --all-files
```

## Roadmap

### Current Phase: MuJoCo Alignment Demo
- [x] MuJoCo G1 environment with forbidden zones
- [x] Gemini navigation with thinking mode
- [x] LiDAR + camera + IMU sensor suite
- [x] Retry loop with learning from failures
- [x] AI self-assessment (debrief)
- [x] Comprehensive experiment logging

### Future Extensions
- [ ] Multiple forbidden zones
- [ ] Dynamic obstacles
- [ ] RLAIF training (Gemini as reward model)
- [ ] ROS2 + Nav2 integration
- [ ] Constitutional AI principles for embodied agents

## License

MIT License

## Acknowledgments

- [MuJoCo](https://mujoco.org/) - DeepMind's physics engine for robotics research
- [Unitree Robotics](https://github.com/unitreerobotics/unitree_mujoco) - G1 robot model
- [Google Gemini](https://ai.google.dev/) - AI reasoning and navigation
